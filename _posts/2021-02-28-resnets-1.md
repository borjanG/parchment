---
layout: post
title: "ResNets and Neural ODEs"
tags: [math, cs]
---

It is superfluous to state the impact deep (machine) learning has had on modern technology, as it powers many tools of modern society, ranging from web searches to content filtering on social networks [1]. It is also increasingly present in consumer products such as cameras, smartphones and automobiles. 

From a mathematical point of view however, a large number of the employed models and techniques remain rather ad hoc.

## ResNets

Neural networks are the workhorse models of deep learning, and the main reason behind the (perhaps unreasonable) effectiveness of the latter in practice.
Residual neural networks are a very specific, compound neural network architecture which has shown state of the art performance on a variety of image processing tasks.
In fact, the original paper on ResNets (see He et al.) is the most cited paper (per Google Scholar) in all scientific disciplines of the 2010s. 

Let us recall that, in supervised learning, we are generally interested in approximating a function 

$$
f: \mathcal{X} \to \mathcal{Y}
$$ 

which is unknown a priori, and we only dispose of a dataset of $S$ distinct points:

$$
\{\vec{x}_i, \vec{y}_i = f(\vec{x}_i) \}_{i=1}^N.
$$

We approximate $f$ by using the "flow"-map of the discrete-time dynamical system

$$
\begin{cases}
z_i^{k+1} = z_i^k + \sigma(A^k z_i^k + b^k) &\text{ for } k = 0, \ldots, L-1 \\
z_i^0 = \vec{x}_i \in \mathbf{R}^d.
\end{cases}
$$

---
## References.

[1] LeCun, Y., Bengio, Y., and Hinton, G. (2015). Deep learning. Nature,
521(7553):436–444.

[2] He, K., Zhang, X., Ren, S., and Sun, J. (2016). Deep residual learning for image
recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages
770–778.

[5] Léon Bottou, Frank E. Curtis and Jorge Nocedal: Optimization Methods for Large-Scale Machine Learning, Siam Review, 60(2):223-311, 2018.

[8] Weinan, E. (2017). A proposal on machine learning via dynamical systems. Communications in Mathematics and Statistics, 5(1):1–11.